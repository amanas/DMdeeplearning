{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation \n",
    "examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import os.path\n",
    "\n",
    "\n",
    "train_data_dir = '../data/train'\n",
    "validation_data_dir = '../data/validation'\n",
    "\n",
    "train_features_path = '{}_train_features.npy'\n",
    "train_labels_path = '{}_train_labels.npy'\n",
    "validation_features_path = '{}_validation_features.npy'\n",
    "validation_labels_path = '{}_validation_labels.npy'\n",
    "weights_path = '{}_top_model.h5'\n",
    "\n",
    "# TODO: set properly\n",
    "width, height = 200, 200\n",
    "train_samples = 1152\n",
    "validation_samples = 288\n",
    "categories = 21\n",
    "batch_size = 4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def is_train_data_generated(name):\n",
    "    return os.path.isfile(train_features_path.format(name)) \\\n",
    "       and os.path.isfile(train_labels_path.format(name))\n",
    "\n",
    "def generate_train_data(name, model):\n",
    "    \n",
    "    print 'generating train data'\n",
    "    \n",
    "    naive_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    \n",
    "    dataflow = naive_datagen.flow_from_directory(train_data_dir, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 class_mode='categorical',\n",
    "                                                 target_size=(width, height),\n",
    "                                                 shuffle=False)\n",
    "\n",
    "    features = None\n",
    "    labels = None    \n",
    "    rounds = train_samples // batch_size\n",
    "    print 'running {} rounds'.format(rounds)\n",
    "    for i in range(rounds):\n",
    "        if i % 50 == 0:\n",
    "            print\n",
    "            print i,'/',rounds,'.',\n",
    "        else:\n",
    "            print '.',\n",
    "        batch = dataflow.next()\n",
    "        batch_features = model.predict(batch[0])\n",
    "        batch_labels = batch[1]\n",
    "\n",
    "        if features is None:\n",
    "            features = batch_features\n",
    "        else:\n",
    "            features = np.append(features,batch_features,axis=0)\n",
    "\n",
    "        if labels is None:\n",
    "            labels = batch_labels\n",
    "        else:\n",
    "            labels = np.append(labels,batch_labels,axis=0)\n",
    "            \n",
    "    np.save(open(train_features_path.format(name), 'w'), features)\n",
    "    np.save(open(train_labels_path.format(name), 'w'), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def is_validation_data_generated(name):\n",
    "    return os.path.isfile(validation_features_path.format(name)) \\\n",
    "       and os.path.isfile(validation_labels_path.format(name))\n",
    "\n",
    "def generate_validation_data(name, model):\n",
    "    \n",
    "    print 'generating validation data'\n",
    "    \n",
    "    naive_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    \n",
    "    dataflow = naive_datagen.flow_from_directory(validation_data_dir, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 class_mode='categorical',\n",
    "                                                 target_size=(width, height),\n",
    "                                                 shuffle=False)\n",
    "\n",
    "    features = None\n",
    "    labels = None    \n",
    "    rounds = validation_samples // batch_size\n",
    "    print 'running {} rounds'.format(rounds)\n",
    "    for i in range(rounds):\n",
    "        if i % 50 == 0:\n",
    "            print\n",
    "            print i,'/',rounds,'.',\n",
    "        else:\n",
    "            print '.',\n",
    "        batch = dataflow.next()\n",
    "        batch_features = model.predict(batch[0])\n",
    "        batch_labels = batch[1]\n",
    "\n",
    "        if features is None:\n",
    "            features = batch_features\n",
    "        else:\n",
    "            features = np.append(features,batch_features,axis=0)\n",
    "\n",
    "        if labels is None:\n",
    "            labels = batch_labels\n",
    "        else:\n",
    "            labels = np.append(labels,batch_labels,axis=0)\n",
    "            \n",
    "    np.save(open(validation_features_path.format(name), 'w'), features)\n",
    "    np.save(open(validation_labels_path.format(name), 'w'), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating validation data\n",
      "Found 288 images belonging to 21 classes.\n",
      "running 72 rounds\n",
      "\n",
      "0 / 72 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "50 / 72 . . . . ."
     ]
    }
   ],
   "source": [
    "def do_VGG16_exp1():    \n",
    "    name = 'VGG16_exp1'\n",
    "       \n",
    "    if not is_train_data_generated(name):\n",
    "        VGG16 = applications.VGG16(include_top=False, weights='imagenet')\n",
    "        generate_train_data(name,VGG16)\n",
    "        \n",
    "    if not is_validation_data_generated(name):\n",
    "        VGG16 = applications.VGG16(include_top=False, weights='imagenet')\n",
    "        generate_validation_data(name,VGG16)\n",
    "    \n",
    "    print 'training the top model'\n",
    "    \n",
    "    train_features = np.load(open(train_features_path.format(name)))\n",
    "    train_labels = np.load(open(train_labels_path.format(name)))\n",
    "    validation_features = np.load(open(validation_features_path.format(name)))\n",
    "    validation_labels = np.load(open(validation_labels_path.format(name)))\n",
    "\n",
    "    print train_features.shape\n",
    "    print train_labels.shape\n",
    "    print validation_features.shape\n",
    "    print validation_labels.shape\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_features,\n",
    "              train_labels,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=epochs,\n",
    "              validation_data=(validation_features, validation_labels))\n",
    "    model.save_weights(weights_path.format(name))\n",
    "\n",
    "do_VGG16_exp1()\n",
    "\n",
    "# # revisar esto para hacer checkpoints\n",
    "# # http://stackoverflow.com/questions/35074549/how-to-load-a-model-from-an-hdf5-file-in-keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

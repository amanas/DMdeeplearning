{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''This script goes along the blog post\n",
    "\"Building powerful image classification models using very little data\"\n",
    "from blog.keras.io.\n",
    "It uses data that can be downloaded at:\n",
    "https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "In our setup, we:\n",
    "- created a data/ folder\n",
    "- created train/ and validation/ subfolders inside data/\n",
    "- created cats/ and dogs/ subfolders inside train/ and validation/\n",
    "- put the cat pictures index 0-999 in data/train/cats\n",
    "- put the cat pictures index 1000-1400 in data/validation/cats\n",
    "- put the dogs pictures index 12500-13499 in data/train/dogs\n",
    "- put the dog pictures index 13500-13900 in data/validation/dogs\n",
    "So that we have 1000 training examples for each class, and 400 validation \n",
    "examples for each class.\n",
    "In summary, this is our directory structure:\n",
    "```\n",
    "data/\n",
    "    train/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "    validation/\n",
    "        dogs/\n",
    "            dog001.jpg\n",
    "            dog002.jpg\n",
    "            ...\n",
    "        cats/\n",
    "            cat001.jpg\n",
    "            cat002.jpg\n",
    "            ...\n",
    "```\n",
    "'''\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "\n",
    "train_data_dir = '../data/train'\n",
    "validation_data_dir = '../data/validation'\n",
    "\n",
    "train_features_path = 'VGG16_exp1_train_features.npy'\n",
    "train_labels_path = 'VGG16_exp1_train_labels.npy'\n",
    "validation_features_path = 'VGG16_exp1_validation_features.npy'\n",
    "validation_labels_path = 'VGG16_exp1_validation_labels.npy'\n",
    "weights_path = 'VGG16_exp1_top_model.h5'\n",
    "\n",
    "# TODO: set properly\n",
    "width, height = 150, 150\n",
    "train_samples = 1152\n",
    "validation_samples = 288\n",
    "batch_size = 4\n",
    "epochs = 20\n",
    "\n",
    "# build the VGG16 network\n",
    "# VGG16 = applications.VGG16(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_train_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(width, height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    train_features = VGG16.predict_generator(generator,\n",
    "                                             train_samples // batch_size)\n",
    "    np.save(open(train_features_path, 'w'), train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_train_labels():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        batch_size=batch_size * (nb_train_samples // batch_size),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    train_labels = generator.next()[1]\n",
    "    np.save(open(train_labels_path, 'w'), train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_validation_features():\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(width, height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    validation_features = VGG16.predict_generator(\n",
    "        generator, validation_samples // batch_size)\n",
    "    np.save(open(validation_features_path, 'w'), validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_validation_labels():\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        batch_size=batch_size * (nb_validation_samples // batch_size),\n",
    "        class_mode='categorical',\n",
    "        shuffle=False)\n",
    "    validation_labels = generator.next()[1]\n",
    "    np.save(open(validation_labels_path, 'w'), validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_features = np.load(open(train_features_path)).reshape((1152, 4, 512))\n",
    "    train_labels = np.load(open(train_labels_path))\n",
    "\n",
    "    validation_features = np.load(open(validation_features_path)).reshape(\n",
    "        (288, 4, 512))\n",
    "    validation_labels = np.load(open(validation_labels_path))\n",
    "\n",
    "    print train_features.shape\n",
    "    print train_labels.shape\n",
    "    print validation_features.shape\n",
    "    print validation_labels.shape\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_features.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(21, activation='softmax'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_features,\n",
    "              train_labels,\n",
    "              batch_size=batch_size,\n",
    "              nb_epoch=epochs,\n",
    "              validation_data=(validation_features, validation_labels))\n",
    "    model.save_weights(weights_path)\n",
    "\n",
    "\n",
    "# generate_train_features()\n",
    "# generate_train_labels()\n",
    "# generate_validation_features()\n",
    "# generate_validation_labels()\n",
    "\n",
    "train_top_model()\n",
    "\n",
    "# revisar esto para hacer checkpoints\n",
    "# http://stackoverflow.com/questions/35074549/how-to-load-a-model-from-an-hdf5-file-in-keras"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tunning de redes preentranadas\n",
    "\n",
    "Los experimentos realizados en este notebook se basan en las indicaciones de este [blog](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html)\n",
    "\n",
    "La idea, básimente consiste en:\n",
    "1. coger una red ya entrenada previamente y quitarle la capa superior\n",
    "2. clarificar nuestro conjunto de datos con la red resultante del paso anterior\n",
    "3. diseñar un modelo sencillo cuyo input es el output del punto 2 y entrenarlo\n",
    "\n",
    "Aparentemente con muy poco cálculo se pueden obtener buenos resultados.\n",
    "\n",
    "En los siguientes experimentos voy a probar el planteamiento anterior utilizando las redes preentrenadas que vienen con defecto con Keras para ver cual de ellas ofrece mejores resultados.\n",
    "\n",
    "Después, una vez seleccionada una, intentaré determinar el optimizar el diseño del modelo superior.\n",
    "\n",
    "## Parámetros comunes para todos los experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "from keras.layers import Input\n",
    "import os.path\n",
    "\n",
    "\n",
    "train_data_dir = '../data/train'\n",
    "validation_data_dir = '../data/validation'\n",
    "\n",
    "train_features_path = '{}_train_features.npy'\n",
    "train_labels_path = '{}_train_labels.npy'\n",
    "validation_features_path = '{}_validation_features.npy'\n",
    "validation_labels_path = '{}_validation_labels.npy'\n",
    "top_model_path = '{}_top_model.h5'\n",
    "history_path = '{}_history.json'\n",
    "\n",
    "# TODO: set properly\n",
    "width, height = 200, 200\n",
    "train_samples = 1152\n",
    "validation_samples = 288\n",
    "categories = 21\n",
    "batch_size = 4\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generación de datos\n",
    "\n",
    "Definimos unas funciones que, dado un modelo preentrenado, permiten traducir nuestros datos en carácterísticas y etiquetas para utilizarse en el top model.\n",
    "\n",
    "Primero para los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_train_data(name, model):\n",
    "    \n",
    "    naive_datagen = ImageDataGenerator(rescale=1. / 255)    \n",
    "    dataflow = naive_datagen.flow_from_directory(train_data_dir, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 class_mode='categorical',\n",
    "                                                 target_size=(width, height),\n",
    "                                                 shuffle=False)\n",
    "\n",
    "    features = None\n",
    "    labels = None    \n",
    "    rounds = train_samples // batch_size\n",
    "    print 'running {} rounds'.format(rounds)\n",
    "    for i in range(rounds):\n",
    "        if i % 50 == 0:\n",
    "            print\n",
    "            print i,'/',rounds,'.',\n",
    "        else:\n",
    "            print '.',\n",
    "        batch = dataflow.next()\n",
    "        batch_features = model.predict(batch[0])\n",
    "        batch_labels = batch[1]\n",
    "\n",
    "        if features is None:\n",
    "            features = batch_features\n",
    "        else:\n",
    "            features = np.append(features,batch_features,axis=0)\n",
    "\n",
    "        if labels is None:\n",
    "            labels = batch_labels\n",
    "        else:\n",
    "            labels = np.append(labels,batch_labels,axis=0)\n",
    "            \n",
    "    np.save(open(train_features_path.format(name), 'w'), features)\n",
    "    np.save(open(train_labels_path.format(name), 'w'), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y ahora para los datos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_validation_data(name, model):\n",
    "    \n",
    "    naive_datagen = ImageDataGenerator(rescale=1. / 255)    \n",
    "    dataflow = naive_datagen.flow_from_directory(validation_data_dir, \n",
    "                                                 batch_size=batch_size, \n",
    "                                                 class_mode='categorical',\n",
    "                                                 target_size=(width, height),\n",
    "                                                 shuffle=False)\n",
    "\n",
    "    features = None\n",
    "    labels = None    \n",
    "    rounds = validation_samples // batch_size\n",
    "    print 'running {} rounds'.format(rounds)\n",
    "    for i in range(rounds):\n",
    "        if i % 50 == 0:\n",
    "            print\n",
    "            print i,'/',rounds,'.',\n",
    "        else:\n",
    "            print '.',\n",
    "        batch = dataflow.next()\n",
    "        batch_features = model.predict(batch[0])\n",
    "        batch_labels = batch[1]\n",
    "\n",
    "        if features is None:\n",
    "            features = batch_features\n",
    "        else:\n",
    "            features = np.append(features,batch_features,axis=0)\n",
    "\n",
    "        if labels is None:\n",
    "            labels = batch_labels\n",
    "        else:\n",
    "            labels = np.append(labels,batch_labels,axis=0)\n",
    "            \n",
    "    np.save(open(validation_features_path.format(name), 'w'), features)\n",
    "    np.save(open(validation_labels_path.format(name), 'w'), labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una función que previene que se repitan experimentos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def is_already_done(name):\n",
    "    return os.path.isfile(validation_features_path.format(name)) \\\n",
    "        or os.path.isfile(validation_labels_path.format(name)) \\\n",
    "        or os.path.isfile(train_features_path.format(name)) \\\n",
    "        or os.path.isfile(train_labels_path.format(name)) \\\n",
    "        or os.path.isfile(top_model_path.format(name)) \n",
    "\n",
    "def plot_history(name):\n",
    "    history = json.load(open(history_path.format(name)))\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history['acc'])\n",
    "    plt.plot(history['val_acc'])\n",
    "    plt.title(name + ' model accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # summarize history for loss\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history['loss'])\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.title(name + ' model loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.grid(True)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top model común"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def common_top_model(input_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=input_shape))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(categories, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutor de experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def run_experiment(name, model):    \n",
    "    \n",
    "    if is_already_done(name):\n",
    "        raise Exception('el experimento parece que ya se ha realizado')\n",
    "        \n",
    "    print 'generating training data'\n",
    "    generate_train_data(name, model)\n",
    "    \n",
    "    print 'generating validation data'\n",
    "    generate_validation_data(name, model)\n",
    "    \n",
    "    print 'loading training data'    \n",
    "    train_features = np.load(open(train_features_path.format(name)))\n",
    "    train_labels = np.load(open(train_labels_path.format(name)))\n",
    "    \n",
    "    print 'loading validation data'    \n",
    "    validation_features = np.load(open(validation_features_path.format(name)))\n",
    "    validation_labels = np.load(open(validation_labels_path.format(name)))\n",
    "\n",
    "    print 'shapes: '\n",
    "    print '\\t',train_features.shape\n",
    "    print '\\t',train_labels.shape\n",
    "    print '\\t',validation_features.shape\n",
    "    print '\\t',validation_labels.shape\n",
    "              \n",
    "    print 'training top model'\n",
    "    top_model = common_top_model(train_features.shape[1:])\n",
    "    top_model.compile(\n",
    "        optimizer='rmsprop',\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    history = top_model.fit(train_features,\n",
    "                            train_labels,\n",
    "                            batch_size=batch_size,\n",
    "                            nb_epoch=epochs,\n",
    "                            validation_data=(validation_features, validation_labels))\n",
    "              \n",
    "    print 'saving top model'\n",
    "    top_model.save(top_model_path.format(name))    \n",
    "    \n",
    "    print history\n",
    "    print history.history\n",
    "    print 'saving history'\n",
    "    \n",
    "    json.dump(history.history, open(history_path.format(name),'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentos \"naive\" con distintas redes preentrenadas\n",
    "### VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def VGG16_exp1():    \n",
    "    name = 'VGG16_exp1'       \n",
    "    input_tensor=Input(shape=(width,height,3))\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet',input_tensor=input_tensor)\n",
    "    run_experiment(name, model)\n",
    "\n",
    "# Comentado porque sólo se ejecuta una vez\n",
    "# VGG16_exp1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def VGG19_exp1():    \n",
    "    name = 'VGG19_exp1'       \n",
    "    input_tensor=Input(shape=(width,height,3))\n",
    "    model = applications.VGG19(include_top=False, weights='imagenet',input_tensor=input_tensor)\n",
    "    run_experiment(name, model)\n",
    "\n",
    "# Comentado porque sólo se ejecuta una vez\n",
    "VGG19_exp1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def InceptionV3_exp1():    \n",
    "    name = 'InceptionV3_exp1'       \n",
    "    input_tensor=Input(shape=(width,height,3))\n",
    "    model = applications.InceptionV3(include_top=False,weights='imagenet',input_tensor=input_tensor)\n",
    "    run_experiment(name,model)\n",
    "    \n",
    "# Comentado porque sólo se ejecuta una vez\n",
    "InceptionV3_exp1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ResNet50_exp1():    \n",
    "    name = 'ResNet50_exp1'       \n",
    "    input_tensor=Input(shape=(width,height,3))\n",
    "    model = applications.ResNet50(include_top=False,weights='imagenet',input_tensor=input_tensor)\n",
    "    run_experiment(name,model)\n",
    "    \n",
    "# Comentado porque sólo se ejecuta una vez\n",
    "ResNet50_exp1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Xception_exp1():    \n",
    "    name = 'Xception_exp1'       \n",
    "    input_tensor=Input(shape=(width,height,3))\n",
    "    model = applications.Xception(include_top=False,weights='imagenet',input_tensor=input_tensor)\n",
    "    run_experiment(name,model)\n",
    "    \n",
    "# Comentado porque sólo se ejecuta una vez\n",
    "Xception_exp1()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Resultados de los experimentos \"naive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot_history('VGG16_exp1')\n",
    "# plot_history('VGG19_exp1')\n",
    "# plot_history('InceptionV3_exp1')\n",
    "# plot_history('ResNet50_exp1')\n",
    "# plot_history('Xception_exp1')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
